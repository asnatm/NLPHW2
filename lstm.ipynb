{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 -  RNN (LSTM) for Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Run the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn.datasets import imdb\n",
    "\n",
    "# IMDB Dataset loading\n",
    "train, test, _ = imdb.load_data(path='imdb.pkl', n_words=10000,\n",
    "                                valid_portion=0.1)\n",
    "trainX, trainY = train\n",
    "testX, testY = test\n",
    "\n",
    "# Data preprocessing\n",
    "# Sequence padding\n",
    "trainX = pad_sequences(trainX, maxlen=100, value=0.)\n",
    "testX = pad_sequences(testX, maxlen=100, value=0.)\n",
    "# Converting labels to binary vectors\n",
    "trainY = to_categorical(trainY, nb_classes=2)\n",
    "testY = to_categorical(testY, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.08254\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.08254 - acc: 0.9837 | val_loss: 0.76012 - val_acc: 0.8088 -- iter: 22500/22500\n",
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.08254\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.08254 - acc: 0.9837 | val_loss: 0.76012 - val_acc: 0.8088 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf reseting\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Network building\n",
    "net = tflearn.input_data([None, 100])\n",
    "net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
    "net = tflearn.lstm(net, 128, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 MLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_words = 10000\n",
    "\n",
    "# IMDB Dataset loading\n",
    "train, test, _ = imdb.load_data(path='imdb.pkl', n_words=n_words,\n",
    "                                valid_portion=0.1)\n",
    "trainX, trainY = train\n",
    "testX, testY = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now convert our X vectors to sentences of one-hot words, for the classifier to work without further embedding. Labels will be adjusted as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sent2vec(sent):\n",
    "    vec = [0] * n_words\n",
    "    for idx in sent:\n",
    "        vec[idx] += 1\n",
    "    return vec\n",
    "\n",
    "# Converting sentence vectors to word count vectors\n",
    "trainX_feat = [sent2vec(sent) for sent in trainX]\n",
    "testX_feat = [sent2vec(sent) for sent in testX]\n",
    "\n",
    "# Converting labels to binary vectors\n",
    "trainY_cat = to_categorical(trainY, nb_classes=2)\n",
    "testY_cat = to_categorical(testY, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf reseting\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Network building\n",
    "net2 = tflearn.input_data([None, n_words])\n",
    "net2 = tflearn.fully_connected(net2, 512, activation='relu')\n",
    "net2 = tflearn.dropout(net2, 0.5)\n",
    "net2 = tflearn.fully_connected(net2, 2, activation='softmax')\n",
    "net2 = tflearn.regression(net2, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.10952\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.10952 - acc: 0.9758 | val_loss: 0.50196 - val_acc: 0.8844 -- iter: 22500/22500\n",
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.10952\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.10952 - acc: 0.9758 | val_loss: 0.50196 - val_acc: 0.8844 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model2 = tflearn.DNN(net2, tensorboard_verbose=0)\n",
    "model2.fit(trainX_feat, trainY_cat, validation_set=(testX_feat, testY_cat), show_metric=True,\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 encode_doc(string) & decode_doc(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from reuters import load_data, get_word_index\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "data = get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "inv_data = {value: key for key, value in data.items()}\n",
    "\n",
    "def encode_doc(string):\n",
    "    return [data[word] for word in word_tokenize(string) if word in data]\n",
    "\n",
    "def decode_doc(ids):\n",
    "    return [inv_data[i] for i in ids if i in inv_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 TFLearn version on the Reuters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# Sequence padding\n",
    "label_num = max(y_train) + 1\n",
    "X_train = pad_sequences(X_train, maxlen=100, value=0.)\n",
    "X_test = pad_sequences(X_test, maxlen=100, value=0.)\n",
    "# Converting labels to binary vectors\n",
    "y_train = to_categorical(y_train, nb_classes=label_num)\n",
    "y_test = to_categorical(y_test, nb_classes=label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TensorFlow resseting\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Network building\n",
    "net3 = tflearn.input_data([None, 100])\n",
    "net3 = tflearn.embedding(net3, input_dim=len(data) + 1, output_dim=128)\n",
    "net3 = tflearn.lstm(net3, 128, dropout=0.8)\n",
    "net3 = tflearn.fully_connected(net3, label_num, activation='softmax')\n",
    "net3 = tflearn.regression(net3, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2810  | total loss: \u001b[1m\u001b[32m0.80846\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.80846 - acc: 0.8031 | val_loss: 1.50635 - val_acc: 0.6523 -- iter: 8982/8982\n",
      "Training Step: 2810  | total loss: \u001b[1m\u001b[32m0.80846\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.80846 - acc: 0.8031 | val_loss: 1.50635 - val_acc: 0.6523 -- iter: 8982/8982\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model3 = tflearn.DNN(net3, tensorboard_verbose=0)\n",
    "model3.fit(X_train, y_train, validation_set=(X_test, y_test), show_metric=True,\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3.3a classify_doc(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_doc(string):\n",
    "    encoded_doc = encode_doc(string)\n",
    "    padded_doc = pad_sequences([encoded_doc], maxlen=100, value=0.)\n",
    "    return model3.predict(padded_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3.3b Explore the Reuters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the Reuters dataset: report on number of classes, number of docs per class, size of docs (number of words per doc) - use Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "0       67\n",
       "1      537\n",
       "2       94\n",
       "3     3972\n",
       "4     2423\n",
       "5       22\n",
       "6       62\n",
       "7       19\n",
       "8      177\n",
       "9      126\n",
       "10     154\n",
       "11     473\n",
       "12      62\n",
       "13     209\n",
       "14      28\n",
       "15      29\n",
       "16     543\n",
       "17      51\n",
       "18      86\n",
       "19     682\n",
       "20     339\n",
       "21     127\n",
       "22      22\n",
       "23      53\n",
       "24      81\n",
       "25     123\n",
       "26      32\n",
       "27      19\n",
       "28      58\n",
       "29      23\n",
       "30      57\n",
       "31      52\n",
       "32      42\n",
       "33      16\n",
       "34      57\n",
       "35      16\n",
       "36      60\n",
       "37      21\n",
       "38      22\n",
       "39      29\n",
       "40      46\n",
       "41      38\n",
       "42      16\n",
       "43      27\n",
       "44      17\n",
       "45      19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reuters import load_data, get_word_index\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "(X, y), (_,_) = load_data(test_split=0.0)\n",
    "data = get_word_index()\n",
    "\n",
    "doc_lengths = [len(x) for x in X]\n",
    "df = DataFrame(list(zip(doc_lengths, y)), columns=[\"length\", \"category\"])\n",
    "df_by_cat = df.groupby(\"category\")\n",
    "df_by_cat.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there are 46 categories. The size of docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>224</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>316</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>527</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>231</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>354</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11198</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11199</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11201</th>\n",
       "      <td>121</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11202</th>\n",
       "      <td>504</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11203</th>\n",
       "      <td>217</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11204</th>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11205</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11208</th>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11209</th>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11210</th>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11211</th>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11212</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11213</th>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11214</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11215</th>\n",
       "      <td>282</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11216</th>\n",
       "      <td>112</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11217</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11218</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11219</th>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11220</th>\n",
       "      <td>396</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11221</th>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11222</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11223</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11224</th>\n",
       "      <td>116</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11225</th>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11226</th>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11227</th>\n",
       "      <td>272</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11228 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       length  category\n",
       "0          87         3\n",
       "1          56         4\n",
       "2         139         3\n",
       "3         224         4\n",
       "4         101         4\n",
       "5         116         4\n",
       "6         100         4\n",
       "7         100         3\n",
       "8          82         3\n",
       "9         106        16\n",
       "10         31         3\n",
       "11         59         3\n",
       "12         65         4\n",
       "13        316         4\n",
       "14        527        19\n",
       "15         76         8\n",
       "16        114        16\n",
       "17         17         3\n",
       "18         91         3\n",
       "19         77        21\n",
       "20        231        11\n",
       "21        108         4\n",
       "22         83         4\n",
       "23         29         3\n",
       "24         95         3\n",
       "25        110         1\n",
       "26         23         3\n",
       "27        373         1\n",
       "28        114         3\n",
       "29        354        16\n",
       "...       ...       ...\n",
       "11198      17         3\n",
       "11199      36        10\n",
       "11200      81         3\n",
       "11201     121        15\n",
       "11202     504        21\n",
       "11203     217        13\n",
       "11204      54         8\n",
       "11205      60        30\n",
       "11206      16        16\n",
       "11207      17         3\n",
       "11208      60         4\n",
       "11209     101        20\n",
       "11210      69         3\n",
       "11211     178        13\n",
       "11212      29         3\n",
       "11213      88         3\n",
       "11214      63         3\n",
       "11215     282        11\n",
       "11216     112        18\n",
       "11217      40         2\n",
       "11218      55         3\n",
       "11219     103        16\n",
       "11220     396         3\n",
       "11221      71         3\n",
       "11222      19         3\n",
       "11223      34         3\n",
       "11224     116         8\n",
       "11225      49         3\n",
       "11226      89         3\n",
       "11227     272        24\n",
       "\n",
       "[11228 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, in a more informative fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGHCAYAAACnPchFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e83acef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df[\"length\"], bins=15, range=(0, 1000))\n",
    "plt.title(\"Docs' Lengths\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Pre-trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TensorFlow resseting\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from reuters import load_data, get_word_index\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "\n",
    "(X_train, y_train), (X_test,y_test) = load_data()\n",
    "data = get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, coded_sents):\n",
    "        self.coded_sents = coded_sents\n",
    " \n",
    "    def __iter__(self):\n",
    "        for coded_sent in self.coded_sents:\n",
    "            yield decode_doc(coded_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Word2Vec model according to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_sents = MySentences(X_train + X_test)\n",
    "w2v_model = Word2Vec(all_sents, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare weights matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.rand(len(data) + 1, 100)\n",
    "for word, idx in data.items():\n",
    "    vec = np.random.rand(100)\n",
    "    if word in w2v_model:\n",
    "        vec = w2v_model[word]\n",
    "    embedding_matrix[idx] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequence padding\n",
    "X_train_padded = pad_sequences(X_train, maxlen=100, value=0.)\n",
    "X_test_padded = pad_sequences(X_test, maxlen=100, value=0.)\n",
    "# Converting labels to binary vectors\n",
    "y_train_cat = to_categorical(y_train, nb_classes=46)\n",
    "y_test_cat = to_categorical(y_test, nb_classes=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TensorFlow resseting\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Network building\n",
    "net4 = tflearn.input_data([None, 100])\n",
    "net4 = tflearn.embedding(net4, input_dim=len(data)+1, output_dim=100, trainable=False, name=\"EmbeddingLayer\")\n",
    "net4 = tflearn.lstm(net4, 128, dropout=0.8)\n",
    "net4 = tflearn.fully_connected(net4, 46, activation='softmax')\n",
    "net4 = tflearn.regression(net4, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\n",
    "\n",
    "model4 = tflearn.DNN(net4, tensorboard_verbose=0)\n",
    "\n",
    "# Retrieve embedding layer weights (only a single weight matrix, so index is 0)\n",
    "embeddingWeights = tflearn.get_layer_variables_by_name('EmbeddingLayer')[0]\n",
    "# Assign your own weights (for example, a numpy array [input_dim, output_dim])\n",
    "model4.set_weights(embeddingWeights, embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2810  | total loss: \u001b[1m\u001b[32m0.95048\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.95048 - acc: 0.7472 | val_loss: 1.08895 - val_acc: 0.7226 -- iter: 8982/8982\n",
      "Training Step: 2810  | total loss: \u001b[1m\u001b[32m0.95048\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.95048 - acc: 0.7472 | val_loss: 1.08895 - val_acc: 0.7226 -- iter: 8982/8982\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model4.fit(X_train_padded, y_train_cat, validation_set=(X_test_padded, y_test_cat), show_metric=True,\n",
    "batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
